{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Feature group with complex feature\"\n",
    "date: 2022-03-14\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature groups with complex feature types, such as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "\n",
    "# pyspark functions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import array, coalesce, concat,  col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe with array type featuers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            array_ft|\n",
      "+---+--------------------+\n",
      "|  0|[0.77395604855596...|\n",
      "|  1|[0.77395604855596...|\n",
      "|  2|[0.77395604855596...|\n",
      "|  3|[0.77395604855596...|\n",
      "|  4|[0.77395604855596...|\n",
      "|  5|[0.77395604855596...|\n",
      "|  6|[0.77395604855596...|\n",
      "|  7|[0.77395604855596...|\n",
      "|  8|[0.77395604855596...|\n",
      "|  9|[0.77395604855596...|\n",
      "| 10|[0.77395604855596...|\n",
      "| 11|[0.77395604855596...|\n",
      "| 12|[0.77395604855596...|\n",
      "| 13|[0.77395604855596...|\n",
      "| 14|[0.77395604855596...|\n",
      "| 15|[0.77395604855596...|\n",
      "| 16|[0.77395604855596...|\n",
      "| 17|[0.77395604855596...|\n",
      "| 18|[0.77395604855596...|\n",
      "| 19|[0.77395604855596...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np_data = []\n",
    "for i in range(1000):\n",
    "    np_data.append([i,default_rng(42).random((100)).tolist()])\n",
    "df_with_complex_ft=sc.parallelize(np_data).toDF(['id','array_ft'])    \n",
    "df_with_complex_ft.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "from hops import hdfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature group with complex type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_hudi_options = {\n",
    "    \"hoodie.bulkinsert.shuffle.parallelism\":\"1\", \n",
    "    \"hoodie.insert.shuffle.parallelism\":\"1\", \n",
    "    \"hoodie.upsert.shuffle.parallelism\":\"1\",\n",
    "    \"hoodie.parquet.compression.ratio\":\"0.5\"\n",
    "}\n",
    "\n",
    "fg_with_complex_ft = fs.create_feature_group(name=\"fg_with_complex_ft\",\n",
    "                                             version=1,\n",
    "                                             primary_key=[\"id\"],\n",
    "                                             description=\"feature group with complex type of features\",\n",
    "                                             time_travel_format=\"HUDI\",     \n",
    "                                             online_enabled=True,                                                \n",
    "                                             statistics_config=False\n",
    "                                            )\n",
    "\n",
    "fg_with_complex_ft.save(df_with_complex_ft, extra_hudi_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset from feature group with complex type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_with_complex_ft = fs.get_feature_group(\"fg_with_complex_ft\",1)\n",
    "query = fg_with_complex_ft.select_all()\n",
    "td = fs.create_training_dataset(name=\"td_with_complex_ft\",\n",
    "                                       version=1,\n",
    "                                       data_format=\"tfrecord\",\n",
    "                                       statistics_config=False, \n",
    "                                       coalesce=True,\n",
    "                                       description=\"training dataset with complex type of features\")\n",
    "td.save(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve feature vector from online feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = fs.get_training_dataset(\"td_with_complex_ft\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.get_serving_vector({\"id\":1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}