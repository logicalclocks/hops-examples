{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eed4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>2</td><td>application_1618520805810_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://resourcemanager.service.consul:8089/proxy/application_1618520805810_0002/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hopsworks0.logicalclocks.com:8044/node/containerlogs/container_e01_1618520805810_0002_01_000001/card_fraud__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType, TimestampType, LongType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab1ff0",
   "metadata": {},
   "source": [
    "# Create empty feature groups \n",
    "We expecting to recieve data from Kafka topic, read using spark streaming, do streamig aggregations and ingest to feature groups. Thus we will create empy feature groups where we will ingest streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269dcfd",
   "metadata": {},
   "source": [
    "### Define schema for feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ef3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_schema = StructType([StructField('tid', StringType(), True),\n",
    "                         StructField('datetime', StringType(), True),\n",
    "                         StructField('cc_num', LongType(), True),\n",
    "                         StructField('amount', DoubleType(), True)])\n",
    "\n",
    "schema_10m = StructType([StructField('cc_num', LongType(), True),\n",
    "                         StructField('num_trans_per_10m', LongType(), True),\n",
    "                         StructField('avg_amt_per_10m', DoubleType(), True),\n",
    "                         StructField('stdev_amt_per_10m', DoubleType(), True)])\n",
    "\n",
    "schema_1h = StructType([StructField('cc_num', LongType(), True),\n",
    "                         StructField('num_trans_per_1h', LongType(), True),\n",
    "                         StructField('avg_amt_per_1h', DoubleType(), True),\n",
    "                         StructField('stdev_amt_per_1h', DoubleType(), True)])\n",
    "\n",
    "schema_12h = StructType([StructField('cc_num', LongType(), True),\n",
    "                         StructField('num_trans_per_12h', LongType(), True),\n",
    "                         StructField('avg_amt_per_12h', DoubleType(), True),\n",
    "                         StructField('stdev_amt_per_12h', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f87cd",
   "metadata": {},
   "source": [
    "### Create empty spark dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c1e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_card_df = sqlContext.createDataFrame(sc.emptyRDD(), card_schema)\n",
    "empty_10m_agg_df = sqlContext.createDataFrame(sc.emptyRDD(), schema_10m)\n",
    "empty_1h_agg_df = sqlContext.createDataFrame(sc.emptyRDD(), schema_1h)\n",
    "empty_12h_agg_df = sqlContext.createDataFrame(sc.emptyRDD(), schema_12h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d5717",
   "metadata": {},
   "source": [
    "### Establish a connection with your Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe10bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "connection = hsfs.connection()\n",
    "# get a reference to the feature store, you can access also shared feature stores by providing the feature store name\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b2675",
   "metadata": {},
   "source": [
    "### Create feature groups. metadata object and save empty spark dataframes to materialise in hopsworks feature store.\n",
    "\n",
    "Now We will create each feature group and enable online feature store. Since we are plannig to use these feature groups durring online model serving primary key(s) are required to retrieve model serving feature vector from online feature store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680d1145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fa7da964d10>"
     ]
    }
   ],
   "source": [
    "card_transactions = fs.create_feature_group(\"card_transactions\", \n",
    "                                              version = 1,\n",
    "                                              online_enabled=True, \n",
    "                                              statistics_config=False, \n",
    "                                              primary_key=[\"tid\"])\n",
    "\n",
    "card_transactions.save(empty_card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4695c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fa7da9d9910>"
     ]
    }
   ],
   "source": [
    "card_transactions_10m_agg = fs.create_feature_group(\"card_transactions_10m_agg\", \n",
    "                                              version = 1,\n",
    "                                              online_enabled=True, \n",
    "                                              statistics_config=False, \n",
    "                                              primary_key=[\"cc_num\"])\n",
    "\n",
    "card_transactions_10m_agg.save(empty_10m_agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a077f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fa7c1d1bd90>"
     ]
    }
   ],
   "source": [
    "card_transactions_1h_agg = fs.create_feature_group(\"card_transactions_1h_agg\", \n",
    "                                              version = 1,\n",
    "                                              online_enabled=True, \n",
    "                                              statistics_config=False, \n",
    "                                              primary_key=[\"cc_num\"])\n",
    "\n",
    "card_transactions_1h_agg.save(empty_1h_agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434547a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fa7da9d9c90>"
     ]
    }
   ],
   "source": [
    "card_transactions_12h_agg = fs.create_feature_group(\"card_transactions_12h_agg\", \n",
    "                                              version = 1,\n",
    "                                              online_enabled=True, \n",
    "                                              statistics_config=False, \n",
    "                                              primary_key=[\"cc_num\"])\n",
    "\n",
    "card_transactions_12h_agg.save(empty_12h_agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9422363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}