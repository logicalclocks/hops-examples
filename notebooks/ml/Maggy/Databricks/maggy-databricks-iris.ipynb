{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Maggy Distributed HPO, Ablation and Training with Tensorflow example\"\n",
    "date: 2021-05-03\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "6fb3f723-2c1d-4d47-8584-2976ca232d5a"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maggy  is an open-source framework that simplifies writing and maintaining distributed machine learning programs.\n",
    "By encapsulating your training logic in a function,\n",
    "the same code can be run unchanged with Python on your laptop or distributed using PySpark for hyperparameter tuning, \n",
    "data-parallel training, or model-parallel training. \n",
    "With the arrival of GPU support in Spark 3.0, \n",
    "PySpark can be now used to orchestrate distributed deep learning applications in TensorFlow and PySpark.  \n",
    "We are pleased to announce we have now added support for Maggy on Databricks, \n",
    "so training machine learning models with many workers should be as easy as running Python programs on your laptop."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Spark Session\n",
    "\n",
    "First, make sure you have a running Spark Session/Context available."
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "0f1528e6-b17f-440c-9380-97b0a27d2eaf"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "e9602de1-25e0-4ae7-88ee-c9182ab01116"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make sure you have the right tensorflow version."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "0a3f0602-b2c7-4799-a11f-7f4e59f9425f"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%pip install tensorflow-cpu==2.4.1\n%pip install scikit-optimize\nimport tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "75c5f372-550d-4f01-be80-70d68f1df449"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting tensorflow-cpu==2.4.1\n  Downloading tensorflow_cpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (144.1 MB)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: google-pasta~=0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.2.0)\nCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: opt-einsum~=3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.3.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\nCollecting tensorboard~=2.4\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\nCollecting tensorflow-estimator&lt;2.5.0,&gt;=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\nRequirement already satisfied: termcolor~=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.0)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\nRequirement already satisfied: typing-extensions~=3.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.7.4.3)\nCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.11.4)\nRequirement already satisfied: h5py~=2.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (2.10.0)\nRequirement already satisfied: astunparse~=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.6.3)\nCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py~=0.10\n  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\nRequirement already satisfied: gast==0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.3.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.2)\nCollecting tensorboard-data-server&lt;0.7.0,&gt;=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.1)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.7.0)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.22.0)\nRequirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.1)\nRequirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (45.2.0.post20200210)\nRequirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.0.0)\nRequirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.11.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.25.8)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.8)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2020.11.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.0.4)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.1.1)\nRequirement already satisfied: rsa&lt;4.1,&gt;=3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.2.8)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.0)\nRequirement already satisfied: pyasn1&gt;=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from rsa&lt;4.1,&gt;=3.1.4-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.8)\nBuilding wheels for collected packages: wrapt\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71068 sha256=5c04cfc7530df7b4bb4f6b905dc6ea61e40dc721cfe0e600eeef4c39b05a1669\n  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built wrapt\nERROR: torch 1.7.0 requires dataclasses, which is not installed.\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.12.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.12.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.12.1 requires sqlalchemy, which is not installed.\nERROR: maggy 0.5.0 has requirement numpy==1.20.1, but you&#39;ll have numpy 1.19.5 which is incompatible.\nInstalling collected packages: flatbuffers, six, numpy, tensorboard-data-server, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, wrapt, tensorflow-cpu\n  Attempting uninstall: six\n    Found existing installation: six 1.14.0\n    Uninstalling six-1.14.0:\n      Successfully uninstalled six-1.14.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.1\n    Uninstalling numpy-1.20.1:\n      Successfully uninstalled numpy-1.20.1\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.9.0\n    Uninstalling absl-py-0.9.0:\n      Successfully uninstalled absl-py-0.9.0\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.27.2\n    Uninstalling grpcio-1.27.2:\n      Successfully uninstalled grpcio-1.27.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.11.2\n    Uninstalling wrapt-1.11.2:\n      Successfully uninstalled wrapt-1.11.2\n  Attempting uninstall: tensorflow-cpu\n    Found existing installation: tensorflow-cpu 2.3.1\n    Uninstalling tensorflow-cpu-2.3.1:\n      Successfully uninstalled tensorflow-cpu-2.3.1\nSuccessfully installed absl-py-0.12.0 flatbuffers-1.12 grpcio-1.32.0 numpy-1.19.5 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-cpu-2.4.1 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: scikit-optimize in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (0.7.4)\nRequirement already satisfied: scipy&gt;=0.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\nRequirement already satisfied: pyaml&gt;=16.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (20.4.0)\nRequirement already satisfied: scikit-learn&gt;=0.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (0.22.1)\nRequirement already satisfied: joblib&gt;=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\nRequirement already satisfied: numpy&gt;=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (1.19.5)\nRequirement already satisfied: PyYAML in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from pyaml&gt;=16.9-&gt;scikit-optimize) (5.3.1)\nPython interpreter will be restarted.\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting tensorflow-cpu==2.4.1\n  Downloading tensorflow_cpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (144.1 MB)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: google-pasta~=0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.2.0)\nCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: opt-einsum~=3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.3.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\nCollecting tensorboard~=2.4\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\nCollecting tensorflow-estimator&lt;2.5.0,&gt;=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\nRequirement already satisfied: termcolor~=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.0)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\nRequirement already satisfied: typing-extensions~=3.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.7.4.3)\nCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.11.4)\nRequirement already satisfied: h5py~=2.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (2.10.0)\nRequirement already satisfied: astunparse~=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.6.3)\nCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py~=0.10\n  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\nRequirement already satisfied: gast==0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.3.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.2)\nCollecting tensorboard-data-server&lt;0.7.0,&gt;=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.1)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.7.0)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.22.0)\nRequirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.1)\nRequirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (45.2.0.post20200210)\nRequirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.0.0)\nRequirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.11.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.25.8)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.8)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2020.11.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.0.4)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.1.1)\nRequirement already satisfied: rsa&lt;4.1,&gt;=3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.2.8)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.0)\nRequirement already satisfied: pyasn1&gt;=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from rsa&lt;4.1,&gt;=3.1.4-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.8)\nBuilding wheels for collected packages: wrapt\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71068 sha256=5c04cfc7530df7b4bb4f6b905dc6ea61e40dc721cfe0e600eeef4c39b05a1669\n  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built wrapt\nERROR: torch 1.7.0 requires dataclasses, which is not installed.\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.12.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.12.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.12.1 requires sqlalchemy, which is not installed.\nERROR: maggy 0.5.0 has requirement numpy==1.20.1, but you&#39;ll have numpy 1.19.5 which is incompatible.\nInstalling collected packages: flatbuffers, six, numpy, tensorboard-data-server, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, wrapt, tensorflow-cpu\n  Attempting uninstall: six\n    Found existing installation: six 1.14.0\n    Uninstalling six-1.14.0:\n      Successfully uninstalled six-1.14.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.1\n    Uninstalling numpy-1.20.1:\n      Successfully uninstalled numpy-1.20.1\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.9.0\n    Uninstalling absl-py-0.9.0:\n      Successfully uninstalled absl-py-0.9.0\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.27.2\n    Uninstalling grpcio-1.27.2:\n      Successfully uninstalled grpcio-1.27.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.11.2\n    Uninstalling wrapt-1.11.2:\n      Successfully uninstalled wrapt-1.11.2\n  Attempting uninstall: tensorflow-cpu\n    Found existing installation: tensorflow-cpu 2.3.1\n    Uninstalling tensorflow-cpu-2.3.1:\n      Successfully uninstalled tensorflow-cpu-2.3.1\nSuccessfully installed absl-py-0.12.0 flatbuffers-1.12 grpcio-1.32.0 numpy-1.19.5 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-cpu-2.4.1 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: scikit-optimize in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (0.7.4)\nRequirement already satisfied: scipy&gt;=0.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\nRequirement already satisfied: pyaml&gt;=16.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (20.4.0)\nRequirement already satisfied: scikit-learn&gt;=0.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (0.22.1)\nRequirement already satisfied: joblib&gt;=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\nRequirement already satisfied: numpy&gt;=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from scikit-optimize) (1.19.5)\nRequirement already satisfied: PyYAML in /local_disk0/.ephemeral_nfs/envs/pythonEnv-e805b4c7-3fed-413f-8bec-9ff7b31c6903/lib/python3.7/site-packages (from pyaml&gt;=16.9-&gt;scikit-optimize) (5.3.1)\nPython interpreter will be restarted.\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Model definition\n\nLet's define the model we want to train. The layers of the model have to be defined in the \\_\\_init__ function.\n\nDo not instantiate the class, otherwise you won't be able to use Maggy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "6dffedc6-f4a4-4952-b171-c93ebbb51316"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow import keras \nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\n# you can use keras.Sequential(), you just need to override it \n# on a custom class and define the layers in __init__()\nclass NeuralNetwork(Sequential):\n        \n    def __init__(self, nl=4):\n        \n        super().__init__()\n        self.add(Dense(10,input_shape=(None,4),activation='tanh'))\n        if nl >= 4:\n          for i in range(0, nl-2):\n            self.add(Dense(8,activation='tanh'))\n        self.add(Dense(3,activation='softmax'))\n\nmodel = NeuralNetwork"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "9d6f1fbb-6a2c-4d5d-9de3-2ca2541ec65e"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Dataset creation\n\nIn this example, we are using the iris dataset. Let's download the dataset from https://www.kaggle.com/uciml/iris and upload it on your Databricks profile.\n\nYou can process the dataset in the notebook and pass it to the configuration classes, or process it during the experiment.\nIn order to do that you have to wrap the processing logic in a function and pass it to the training configuration (this step is currently supported only by TfDistributedConfig).\n\nYou need to change the dataset path is correct."
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "fdcb2817-3b0e-4f03-87f4-3e066384ed82"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/Iris.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "c0bbdf75-e3d8-484d-baa8-16a7afd382eb"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "overflow": false,
       "datasetInfos": [],
       "data": [
        [
         "dbfs:/FileStore/tables/Iris.csv",
         "Iris.csv",
         5107
        ]
       ],
       "plotOptions": {
        "displayType": "table",
        "customPlotOptions": {},
        "pivotColumns": [],
        "pivotAggregation": null,
        "xColumns": [],
        "yColumns": []
       },
       "columnCustomDisplayInfos": {},
       "aggType": "",
       "isJsonSchema": true,
       "removedWidgets": [],
       "aggSchema": [],
       "schema": [
        {
         "name": "path",
         "type": "\"string\"",
         "metadata": "{}"
        },
        {
         "name": "name",
         "type": "\"string\"",
         "metadata": "{}"
        },
        {
         "name": "size",
         "type": "\"long\"",
         "metadata": "{}"
        }
       ],
       "aggError": "",
       "aggData": [],
       "addedWidgets": {},
       "metadata": {},
       "dbfsResultPath": null,
       "type": "table",
       "aggOverflow": false,
       "aggSeriesLimitReached": false,
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/Iris.csv</td><td>Iris.csv</td><td>5107</td></tr></tbody></table></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = \"dbfs:/FileStore/tables/Iris.csv\"\n\ntrain_set, test_set = spark.read.format(\"csv\").option(\"header\",\"true\")\\\n  .option(\"inferSchema\", \"true\").load(dataset_path).drop('_c0').randomSplit((0.80, 0.20), seed=0)\n\n\nraw_train_set = train_set.toPandas().values\nraw_test_set = test_set.toPandas().values\n\nraw_train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "c15ffc96-470d-4bb0-8e5a-1b5e4277c806"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[3]: array([[1, 5.1, 3.5, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [2, 4.9, 3.0, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [3, 4.7, 3.2, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [4, 4.6, 3.1, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [5, 5.0, 3.6, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [6, 5.4, 3.9, 1.7, 0.4, &#39;Iris-setosa&#39;],\n       [7, 4.6, 3.4, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [8, 5.0, 3.4, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [9, 4.4, 2.9, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [10, 4.9, 3.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [11, 5.4, 3.7, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [12, 4.8, 3.4, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [13, 4.8, 3.0, 1.4, 0.1, &#39;Iris-setosa&#39;],\n       [14, 4.3, 3.0, 1.1, 0.1, &#39;Iris-setosa&#39;],\n       [15, 5.8, 4.0, 1.2, 0.2, &#39;Iris-setosa&#39;],\n       [16, 5.7, 4.4, 1.5, 0.4, &#39;Iris-setosa&#39;],\n       [17, 5.4, 3.9, 1.3, 0.4, &#39;Iris-setosa&#39;],\n       [18, 5.1, 3.5, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [19, 5.7, 3.8, 1.7, 0.3, &#39;Iris-setosa&#39;],\n       [20, 5.1, 3.8, 1.5, 0.3, &#39;Iris-setosa&#39;],\n       [23, 4.6, 3.6, 1.0, 0.2, &#39;Iris-setosa&#39;],\n       [24, 5.1, 3.3, 1.7, 0.5, &#39;Iris-setosa&#39;],\n       [25, 4.8, 3.4, 1.9, 0.2, &#39;Iris-setosa&#39;],\n       [26, 5.0, 3.0, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [27, 5.0, 3.4, 1.6, 0.4, &#39;Iris-setosa&#39;],\n       [28, 5.2, 3.5, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [32, 5.4, 3.4, 1.5, 0.4, &#39;Iris-setosa&#39;],\n       [33, 5.2, 4.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [34, 5.5, 4.2, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [35, 4.9, 3.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [36, 5.0, 3.2, 1.2, 0.2, &#39;Iris-setosa&#39;],\n       [39, 4.4, 3.0, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [41, 5.0, 3.5, 1.3, 0.3, &#39;Iris-setosa&#39;],\n       [42, 4.5, 2.3, 1.3, 0.3, &#39;Iris-setosa&#39;],\n       [43, 4.4, 3.2, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [44, 5.0, 3.5, 1.6, 0.6, &#39;Iris-setosa&#39;],\n       [45, 5.1, 3.8, 1.9, 0.4, &#39;Iris-setosa&#39;],\n       [46, 4.8, 3.0, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [47, 5.1, 3.8, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [48, 4.6, 3.2, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [49, 5.3, 3.7, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [51, 7.0, 3.2, 4.7, 1.4, &#39;Iris-versicolor&#39;],\n       [52, 6.4, 3.2, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [53, 6.9, 3.1, 4.9, 1.5, &#39;Iris-versicolor&#39;],\n       [55, 6.5, 2.8, 4.6, 1.5, &#39;Iris-versicolor&#39;],\n       [56, 5.7, 2.8, 4.5, 1.3, &#39;Iris-versicolor&#39;],\n       [57, 6.3, 3.3, 4.7, 1.6, &#39;Iris-versicolor&#39;],\n       [58, 4.9, 2.4, 3.3, 1.0, &#39;Iris-versicolor&#39;],\n       [59, 6.6, 2.9, 4.6, 1.3, &#39;Iris-versicolor&#39;],\n       [60, 5.2, 2.7, 3.9, 1.4, &#39;Iris-versicolor&#39;],\n       [64, 6.1, 2.9, 4.7, 1.4, &#39;Iris-versicolor&#39;],\n       [65, 5.6, 2.9, 3.6, 1.3, &#39;Iris-versicolor&#39;],\n       [67, 5.6, 3.0, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [68, 5.8, 2.7, 4.1, 1.0, &#39;Iris-versicolor&#39;],\n       [69, 6.2, 2.2, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [70, 5.6, 2.5, 3.9, 1.1, &#39;Iris-versicolor&#39;],\n       [71, 5.9, 3.2, 4.8, 1.8, &#39;Iris-versicolor&#39;],\n       [72, 6.1, 2.8, 4.0, 1.3, &#39;Iris-versicolor&#39;],\n       [74, 6.1, 2.8, 4.7, 1.2, &#39;Iris-versicolor&#39;],\n       [75, 6.4, 2.9, 4.3, 1.3, &#39;Iris-versicolor&#39;],\n       [77, 6.8, 2.8, 4.8, 1.4, &#39;Iris-versicolor&#39;],\n       [78, 6.7, 3.0, 5.0, 1.7, &#39;Iris-versicolor&#39;],\n       [79, 6.0, 2.9, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [80, 5.7, 2.6, 3.5, 1.0, &#39;Iris-versicolor&#39;],\n       [81, 5.5, 2.4, 3.8, 1.1, &#39;Iris-versicolor&#39;],\n       [82, 5.5, 2.4, 3.7, 1.0, &#39;Iris-versicolor&#39;],\n       [83, 5.8, 2.7, 3.9, 1.2, &#39;Iris-versicolor&#39;],\n       [84, 6.0, 2.7, 5.1, 1.6, &#39;Iris-versicolor&#39;],\n       [85, 5.4, 3.0, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [86, 6.0, 3.4, 4.5, 1.6, &#39;Iris-versicolor&#39;],\n       [87, 6.7, 3.1, 4.7, 1.5, &#39;Iris-versicolor&#39;],\n       [89, 5.6, 3.0, 4.1, 1.3, &#39;Iris-versicolor&#39;],\n       [92, 6.1, 3.0, 4.6, 1.4, &#39;Iris-versicolor&#39;],\n       [93, 5.8, 2.6, 4.0, 1.2, &#39;Iris-versicolor&#39;],\n       [94, 5.0, 2.3, 3.3, 1.0, &#39;Iris-versicolor&#39;],\n       [95, 5.6, 2.7, 4.2, 1.3, &#39;Iris-versicolor&#39;],\n       [96, 5.7, 3.0, 4.2, 1.2, &#39;Iris-versicolor&#39;],\n       [97, 5.7, 2.9, 4.2, 1.3, &#39;Iris-versicolor&#39;],\n       [98, 6.2, 2.9, 4.3, 1.3, &#39;Iris-versicolor&#39;],\n       [99, 5.1, 2.5, 3.0, 1.1, &#39;Iris-versicolor&#39;],\n       [100, 5.7, 2.8, 4.1, 1.3, &#39;Iris-versicolor&#39;],\n       [102, 5.8, 2.7, 5.1, 1.9, &#39;Iris-virginica&#39;],\n       [103, 7.1, 3.0, 5.9, 2.1, &#39;Iris-virginica&#39;],\n       [104, 6.3, 2.9, 5.6, 1.8, &#39;Iris-virginica&#39;],\n       [106, 7.6, 3.0, 6.6, 2.1, &#39;Iris-virginica&#39;],\n       [107, 4.9, 2.5, 4.5, 1.7, &#39;Iris-virginica&#39;],\n       [109, 6.7, 2.5, 5.8, 1.8, &#39;Iris-virginica&#39;],\n       [110, 7.2, 3.6, 6.1, 2.5, &#39;Iris-virginica&#39;],\n       [113, 6.8, 3.0, 5.5, 2.1, &#39;Iris-virginica&#39;],\n       [114, 5.7, 2.5, 5.0, 2.0, &#39;Iris-virginica&#39;],\n       [115, 5.8, 2.8, 5.1, 2.4, &#39;Iris-virginica&#39;],\n       [116, 6.4, 3.2, 5.3, 2.3, &#39;Iris-virginica&#39;],\n       [117, 6.5, 3.0, 5.5, 1.8, &#39;Iris-virginica&#39;],\n       [118, 7.7, 3.8, 6.7, 2.2, &#39;Iris-virginica&#39;],\n       [119, 7.7, 2.6, 6.9, 2.3, &#39;Iris-virginica&#39;],\n       [123, 7.7, 2.8, 6.7, 2.0, &#39;Iris-virginica&#39;],\n       [124, 6.3, 2.7, 4.9, 1.8, &#39;Iris-virginica&#39;],\n       [126, 7.2, 3.2, 6.0, 1.8, &#39;Iris-virginica&#39;],\n       [127, 6.2, 2.8, 4.8, 1.8, &#39;Iris-virginica&#39;],\n       [128, 6.1, 3.0, 4.9, 1.8, &#39;Iris-virginica&#39;],\n       [129, 6.4, 2.8, 5.6, 2.1, &#39;Iris-virginica&#39;],\n       [130, 7.2, 3.0, 5.8, 1.6, &#39;Iris-virginica&#39;],\n       [132, 7.9, 3.8, 6.4, 2.0, &#39;Iris-virginica&#39;],\n       [133, 6.4, 2.8, 5.6, 2.2, &#39;Iris-virginica&#39;],\n       [134, 6.3, 2.8, 5.1, 1.5, &#39;Iris-virginica&#39;],\n       [136, 7.7, 3.0, 6.1, 2.3, &#39;Iris-virginica&#39;],\n       [137, 6.3, 3.4, 5.6, 2.4, &#39;Iris-virginica&#39;],\n       [138, 6.4, 3.1, 5.5, 1.8, &#39;Iris-virginica&#39;],\n       [139, 6.0, 3.0, 4.8, 1.8, &#39;Iris-virginica&#39;],\n       [140, 6.9, 3.1, 5.4, 2.1, &#39;Iris-virginica&#39;],\n       [141, 6.7, 3.1, 5.6, 2.4, &#39;Iris-virginica&#39;],\n       [142, 6.9, 3.1, 5.1, 2.3, &#39;Iris-virginica&#39;],\n       [143, 5.8, 2.7, 5.1, 1.9, &#39;Iris-virginica&#39;],\n       [144, 6.8, 3.2, 5.9, 2.3, &#39;Iris-virginica&#39;],\n       [145, 6.7, 3.3, 5.7, 2.5, &#39;Iris-virginica&#39;],\n       [146, 6.7, 3.0, 5.2, 2.3, &#39;Iris-virginica&#39;],\n       [147, 6.3, 2.5, 5.0, 1.9, &#39;Iris-virginica&#39;],\n       [148, 6.5, 3.0, 5.2, 2.0, &#39;Iris-virginica&#39;],\n       [149, 6.2, 3.4, 5.4, 2.3, &#39;Iris-virginica&#39;],\n       [150, 5.9, 3.0, 5.1, 1.8, &#39;Iris-virginica&#39;]], dtype=object)</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: array([[1, 5.1, 3.5, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [2, 4.9, 3.0, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [3, 4.7, 3.2, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [4, 4.6, 3.1, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [5, 5.0, 3.6, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [6, 5.4, 3.9, 1.7, 0.4, &#39;Iris-setosa&#39;],\n       [7, 4.6, 3.4, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [8, 5.0, 3.4, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [9, 4.4, 2.9, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [10, 4.9, 3.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [11, 5.4, 3.7, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [12, 4.8, 3.4, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [13, 4.8, 3.0, 1.4, 0.1, &#39;Iris-setosa&#39;],\n       [14, 4.3, 3.0, 1.1, 0.1, &#39;Iris-setosa&#39;],\n       [15, 5.8, 4.0, 1.2, 0.2, &#39;Iris-setosa&#39;],\n       [16, 5.7, 4.4, 1.5, 0.4, &#39;Iris-setosa&#39;],\n       [17, 5.4, 3.9, 1.3, 0.4, &#39;Iris-setosa&#39;],\n       [18, 5.1, 3.5, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [19, 5.7, 3.8, 1.7, 0.3, &#39;Iris-setosa&#39;],\n       [20, 5.1, 3.8, 1.5, 0.3, &#39;Iris-setosa&#39;],\n       [23, 4.6, 3.6, 1.0, 0.2, &#39;Iris-setosa&#39;],\n       [24, 5.1, 3.3, 1.7, 0.5, &#39;Iris-setosa&#39;],\n       [25, 4.8, 3.4, 1.9, 0.2, &#39;Iris-setosa&#39;],\n       [26, 5.0, 3.0, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [27, 5.0, 3.4, 1.6, 0.4, &#39;Iris-setosa&#39;],\n       [28, 5.2, 3.5, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [32, 5.4, 3.4, 1.5, 0.4, &#39;Iris-setosa&#39;],\n       [33, 5.2, 4.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [34, 5.5, 4.2, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [35, 4.9, 3.1, 1.5, 0.1, &#39;Iris-setosa&#39;],\n       [36, 5.0, 3.2, 1.2, 0.2, &#39;Iris-setosa&#39;],\n       [39, 4.4, 3.0, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [41, 5.0, 3.5, 1.3, 0.3, &#39;Iris-setosa&#39;],\n       [42, 4.5, 2.3, 1.3, 0.3, &#39;Iris-setosa&#39;],\n       [43, 4.4, 3.2, 1.3, 0.2, &#39;Iris-setosa&#39;],\n       [44, 5.0, 3.5, 1.6, 0.6, &#39;Iris-setosa&#39;],\n       [45, 5.1, 3.8, 1.9, 0.4, &#39;Iris-setosa&#39;],\n       [46, 4.8, 3.0, 1.4, 0.3, &#39;Iris-setosa&#39;],\n       [47, 5.1, 3.8, 1.6, 0.2, &#39;Iris-setosa&#39;],\n       [48, 4.6, 3.2, 1.4, 0.2, &#39;Iris-setosa&#39;],\n       [49, 5.3, 3.7, 1.5, 0.2, &#39;Iris-setosa&#39;],\n       [51, 7.0, 3.2, 4.7, 1.4, &#39;Iris-versicolor&#39;],\n       [52, 6.4, 3.2, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [53, 6.9, 3.1, 4.9, 1.5, &#39;Iris-versicolor&#39;],\n       [55, 6.5, 2.8, 4.6, 1.5, &#39;Iris-versicolor&#39;],\n       [56, 5.7, 2.8, 4.5, 1.3, &#39;Iris-versicolor&#39;],\n       [57, 6.3, 3.3, 4.7, 1.6, &#39;Iris-versicolor&#39;],\n       [58, 4.9, 2.4, 3.3, 1.0, &#39;Iris-versicolor&#39;],\n       [59, 6.6, 2.9, 4.6, 1.3, &#39;Iris-versicolor&#39;],\n       [60, 5.2, 2.7, 3.9, 1.4, &#39;Iris-versicolor&#39;],\n       [64, 6.1, 2.9, 4.7, 1.4, &#39;Iris-versicolor&#39;],\n       [65, 5.6, 2.9, 3.6, 1.3, &#39;Iris-versicolor&#39;],\n       [67, 5.6, 3.0, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [68, 5.8, 2.7, 4.1, 1.0, &#39;Iris-versicolor&#39;],\n       [69, 6.2, 2.2, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [70, 5.6, 2.5, 3.9, 1.1, &#39;Iris-versicolor&#39;],\n       [71, 5.9, 3.2, 4.8, 1.8, &#39;Iris-versicolor&#39;],\n       [72, 6.1, 2.8, 4.0, 1.3, &#39;Iris-versicolor&#39;],\n       [74, 6.1, 2.8, 4.7, 1.2, &#39;Iris-versicolor&#39;],\n       [75, 6.4, 2.9, 4.3, 1.3, &#39;Iris-versicolor&#39;],\n       [77, 6.8, 2.8, 4.8, 1.4, &#39;Iris-versicolor&#39;],\n       [78, 6.7, 3.0, 5.0, 1.7, &#39;Iris-versicolor&#39;],\n       [79, 6.0, 2.9, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [80, 5.7, 2.6, 3.5, 1.0, &#39;Iris-versicolor&#39;],\n       [81, 5.5, 2.4, 3.8, 1.1, &#39;Iris-versicolor&#39;],\n       [82, 5.5, 2.4, 3.7, 1.0, &#39;Iris-versicolor&#39;],\n       [83, 5.8, 2.7, 3.9, 1.2, &#39;Iris-versicolor&#39;],\n       [84, 6.0, 2.7, 5.1, 1.6, &#39;Iris-versicolor&#39;],\n       [85, 5.4, 3.0, 4.5, 1.5, &#39;Iris-versicolor&#39;],\n       [86, 6.0, 3.4, 4.5, 1.6, &#39;Iris-versicolor&#39;],\n       [87, 6.7, 3.1, 4.7, 1.5, &#39;Iris-versicolor&#39;],\n       [89, 5.6, 3.0, 4.1, 1.3, &#39;Iris-versicolor&#39;],\n       [92, 6.1, 3.0, 4.6, 1.4, &#39;Iris-versicolor&#39;],\n       [93, 5.8, 2.6, 4.0, 1.2, &#39;Iris-versicolor&#39;],\n       [94, 5.0, 2.3, 3.3, 1.0, &#39;Iris-versicolor&#39;],\n       [95, 5.6, 2.7, 4.2, 1.3, &#39;Iris-versicolor&#39;],\n       [96, 5.7, 3.0, 4.2, 1.2, &#39;Iris-versicolor&#39;],\n       [97, 5.7, 2.9, 4.2, 1.3, &#39;Iris-versicolor&#39;],\n       [98, 6.2, 2.9, 4.3, 1.3, &#39;Iris-versicolor&#39;],\n       [99, 5.1, 2.5, 3.0, 1.1, &#39;Iris-versicolor&#39;],\n       [100, 5.7, 2.8, 4.1, 1.3, &#39;Iris-versicolor&#39;],\n       [102, 5.8, 2.7, 5.1, 1.9, &#39;Iris-virginica&#39;],\n       [103, 7.1, 3.0, 5.9, 2.1, &#39;Iris-virginica&#39;],\n       [104, 6.3, 2.9, 5.6, 1.8, &#39;Iris-virginica&#39;],\n       [106, 7.6, 3.0, 6.6, 2.1, &#39;Iris-virginica&#39;],\n       [107, 4.9, 2.5, 4.5, 1.7, &#39;Iris-virginica&#39;],\n       [109, 6.7, 2.5, 5.8, 1.8, &#39;Iris-virginica&#39;],\n       [110, 7.2, 3.6, 6.1, 2.5, &#39;Iris-virginica&#39;],\n       [113, 6.8, 3.0, 5.5, 2.1, &#39;Iris-virginica&#39;],\n       [114, 5.7, 2.5, 5.0, 2.0, &#39;Iris-virginica&#39;],\n       [115, 5.8, 2.8, 5.1, 2.4, &#39;Iris-virginica&#39;],\n       [116, 6.4, 3.2, 5.3, 2.3, &#39;Iris-virginica&#39;],\n       [117, 6.5, 3.0, 5.5, 1.8, &#39;Iris-virginica&#39;],\n       [118, 7.7, 3.8, 6.7, 2.2, &#39;Iris-virginica&#39;],\n       [119, 7.7, 2.6, 6.9, 2.3, &#39;Iris-virginica&#39;],\n       [123, 7.7, 2.8, 6.7, 2.0, &#39;Iris-virginica&#39;],\n       [124, 6.3, 2.7, 4.9, 1.8, &#39;Iris-virginica&#39;],\n       [126, 7.2, 3.2, 6.0, 1.8, &#39;Iris-virginica&#39;],\n       [127, 6.2, 2.8, 4.8, 1.8, &#39;Iris-virginica&#39;],\n       [128, 6.1, 3.0, 4.9, 1.8, &#39;Iris-virginica&#39;],\n       [129, 6.4, 2.8, 5.6, 2.1, &#39;Iris-virginica&#39;],\n       [130, 7.2, 3.0, 5.8, 1.6, &#39;Iris-virginica&#39;],\n       [132, 7.9, 3.8, 6.4, 2.0, &#39;Iris-virginica&#39;],\n       [133, 6.4, 2.8, 5.6, 2.2, &#39;Iris-virginica&#39;],\n       [134, 6.3, 2.8, 5.1, 1.5, &#39;Iris-virginica&#39;],\n       [136, 7.7, 3.0, 6.1, 2.3, &#39;Iris-virginica&#39;],\n       [137, 6.3, 3.4, 5.6, 2.4, &#39;Iris-virginica&#39;],\n       [138, 6.4, 3.1, 5.5, 1.8, &#39;Iris-virginica&#39;],\n       [139, 6.0, 3.0, 4.8, 1.8, &#39;Iris-virginica&#39;],\n       [140, 6.9, 3.1, 5.4, 2.1, &#39;Iris-virginica&#39;],\n       [141, 6.7, 3.1, 5.6, 2.4, &#39;Iris-virginica&#39;],\n       [142, 6.9, 3.1, 5.1, 2.3, &#39;Iris-virginica&#39;],\n       [143, 5.8, 2.7, 5.1, 1.9, &#39;Iris-virginica&#39;],\n       [144, 6.8, 3.2, 5.9, 2.3, &#39;Iris-virginica&#39;],\n       [145, 6.7, 3.3, 5.7, 2.5, &#39;Iris-virginica&#39;],\n       [146, 6.7, 3.0, 5.2, 2.3, &#39;Iris-virginica&#39;],\n       [147, 6.3, 2.5, 5.0, 1.9, &#39;Iris-virginica&#39;],\n       [148, 6.5, 3.0, 5.2, 2.0, &#39;Iris-virginica&#39;],\n       [149, 6.2, 3.4, 5.4, 2.3, &#39;Iris-virginica&#39;],\n       [150, 5.9, 3.0, 5.1, 1.8, &#39;Iris-virginica&#39;]], dtype=object)</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also wrap the data processing in a function and pass it to the training configuration, as we'll see later."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "a1ce270e-7db8-4137-acef-ac8bf583ff19"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def process_data(train_set, test_set):\n    \n    import tensorflow as tf\n    from sklearn.preprocessing import LabelBinarizer\n    import numpy as np\n  \n    encoder = LabelBinarizer()\n    \n    X_train = np.asarray(train_set[:,1:5]).astype('float32')\n    y_train = encoder.fit_transform(train_set[:,5])\n    X_test = np.asarray(test_set[:,1:5]).astype('float32')\n    y_test = encoder.fit_transform(test_set[:,5])\n\n    return (X_train, y_train), (X_test, y_test)\n  \ntrain_set, test_set = process_data(raw_train_set, raw_test_set)\n\ntest_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "13cf5223-1f3c-4c97-8b67-aad68fd09b6a"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[4]: (array([[5.4, 3.4, 1.7, 0.2],\n        [5.1, 3.7, 1.5, 0.4],\n        [5.2, 3.4, 1.4, 0.2],\n        [4.7, 3.2, 1.6, 0.2],\n        [4.8, 3.1, 1.6, 0.2],\n        [5.5, 3.5, 1.3, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.1, 3.4, 1.5, 0.2],\n        [5. , 3.3, 1.4, 0.2],\n        [5.5, 2.3, 4. , 1.3],\n        [5. , 2. , 3.5, 1. ],\n        [5.9, 3. , 4.2, 1.5],\n        [6. , 2.2, 4. , 1. ],\n        [6.7, 3.1, 4.4, 1.4],\n        [6.3, 2.5, 4.9, 1.5],\n        [6.6, 3. , 4.4, 1.4],\n        [6.3, 2.3, 4.4, 1.3],\n        [5.5, 2.5, 4. , 1.3],\n        [5.5, 2.6, 4.4, 1.2],\n        [6.3, 3.3, 6. , 2.5],\n        [6.5, 3. , 5.8, 2.2],\n        [7.3, 2.9, 6.3, 1.8],\n        [6.5, 3.2, 5.1, 2. ],\n        [6.4, 2.7, 5.3, 1.9],\n        [6. , 2.2, 5. , 1.5],\n        [6.9, 3.2, 5.7, 2.3],\n        [5.6, 2.8, 4.9, 2. ],\n        [6.7, 3.3, 5.7, 2.1],\n        [7.4, 2.8, 6.1, 1.9],\n        [6.1, 2.6, 5.6, 1.4]], dtype=float32),\n array([[1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1]]))</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: (array([[5.4, 3.4, 1.7, 0.2],\n        [5.1, 3.7, 1.5, 0.4],\n        [5.2, 3.4, 1.4, 0.2],\n        [4.7, 3.2, 1.6, 0.2],\n        [4.8, 3.1, 1.6, 0.2],\n        [5.5, 3.5, 1.3, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.1, 3.4, 1.5, 0.2],\n        [5. , 3.3, 1.4, 0.2],\n        [5.5, 2.3, 4. , 1.3],\n        [5. , 2. , 3.5, 1. ],\n        [5.9, 3. , 4.2, 1.5],\n        [6. , 2.2, 4. , 1. ],\n        [6.7, 3.1, 4.4, 1.4],\n        [6.3, 2.5, 4.9, 1.5],\n        [6.6, 3. , 4.4, 1.4],\n        [6.3, 2.3, 4.4, 1.3],\n        [5.5, 2.5, 4. , 1.3],\n        [5.5, 2.6, 4.4, 1.2],\n        [6.3, 3.3, 6. , 2.5],\n        [6.5, 3. , 5.8, 2.2],\n        [7.3, 2.9, 6.3, 1.8],\n        [6.5, 3.2, 5.1, 2. ],\n        [6.4, 2.7, 5.3, 1.9],\n        [6. , 2.2, 5. , 1.5],\n        [6.9, 3.2, 5.7, 2.3],\n        [5.6, 2.8, 4.9, 2. ],\n        [6.7, 3.3, 5.7, 2.1],\n        [7.4, 2.8, 6.1, 1.9],\n        [6.1, 2.6, 5.6, 1.4]], dtype=float32),\n array([[1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1]]))</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Wrap the training logics.\n\nThe programming model is that you wrap the code containing the logics of your experiment in a function.\n\nFor HPO, we have to define a function that has the HPs to be optimized as parameters. Inside the function we simply put\nthe training logic as we were training our model in a single machine using Tensorflow."
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "37370351-85b5-48c7-803a-d26379d332f9"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def hpo_function(number_layers, reporter):\n  \n  model = NeuralNetwork(nl=number_layers)\n  model.build()\n  \n  #fitting the model and predicting\n  model.compile(Adam(lr=0.04),'categorical_crossentropy',metrics=['accuracy'])\n  train_input, test_input = process_data(raw_train_set, raw_test_set)\n\n  train_batch_size = 75\n  test_batch_size = 15\n  epochs = 10\n  \n  model.fit(x=train_input[0], y=train_input[1],\n            batch_size=train_batch_size,\n            epochs=epochs,\n            verbose=1)\n\n  score = model.evaluate(x=test_input[0], y=test_input[1], batch_size=test_batch_size, verbose=1)\n                         \n  print(f'Test loss: {score[0]}')\n  print(f'Test accuracy: {score[1]}')\n\n  return score[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "3e403a2e-b7e5-41ff-bc7c-fb8f9c3ad532"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "4a1d3a2d-c7ce-4c4e-829b-72b5505c6e3a"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "We do the same for the training function, this time passing the model, train_set, test_set and hparams."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "fa4b77cd-ec40-4acb-8648-ab12d3896195"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def training_function(model, train_set, test_set, hparams):\n    \n    model = model(nl=hparams['number_layers'])\n    model.build()\n    #fitting the model and predicting\n\n    model.compile(Adam(lr=hparams['learning_rate']),'categorical_crossentropy',metrics=['accuracy'])\n    \n    #raise ValueError(list(train_set.as_numpy_iterator()))\n\n    model.fit(train_set,epochs=hparams['epochs'])\n\n    accuracy = model.evaluate(test_set)\n\n    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "d922db38-2c73-4158-a686-b3fa522768fb"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next step we have to create a configuration instance for Maggy. Since in this example we are using Maggy for hyperparameter optimization and distributed training using TensorFlow, we will use OptimizationConfig and TfDistributedConfig.\n\n### 4. Configure and run distributed HPO\n\n\nOptimizationConfig contains the information about the hyperparameter optimization.\nWe need to define a Searchspace class that contains the hyperparameters we want to get optimized. In this example we want to search for the optimal number of layers of the neural network from 2 to 8 layers.\n\nOptimizationConfig the following parameters:\n* num_trials: Controls how many separate runs are conducted during the hp search.\n* optimizer: Optimizer type for searching the hp searchspace.\n* searchspace: A Searchspace object configuring the names, types and ranges of hps.\n* optimization_key: Name of the metric to use for hp search evaluation.\n* direction: Direction of optimization.\n* es_interval: Early stopping polling frequency during an experiment run.\n* es_min: Minimum number of experiments to conduct before starting the early stopping mechanism. Useful to establish a baseline for performance estimates.\n* es_policy: Early stopping policy which formulates a rule for triggering aborts.\n* name: Experiment name.\n* description: A description of the experiment.\n* hb_interval: Heartbeat interval with which the server is polling.\n* fixed_hp: Hyperparamets not to be tuned."
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "ef55d682-0a88-4113-a1f7-79311a783cf6"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from maggy.experiment_config import OptimizationConfig\nfrom maggy import Searchspace\n\n# The searchspace can be instantiated with parameters\nsp = Searchspace(number_layers=('INTEGER', [2, 8]))\n\nhpo_config = OptimizationConfig(num_trials=4, optimizer=\"randomsearch\", searchspace=sp, direction=\"max\", es_interval=1, es_min=5, name=\"hp_tuning_test\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "f53c2b69-a6d9-4822-a2ec-80cd9a189656"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Hyperparameter added: number_layers\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Hyperparameter added: number_layers\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our HPO function and configuration class are now ready, so we can go on and run the HPO experiment. In order to do that, we run the lagom function, passing our training function and the configuration object we instantiated during the last step.\nLagom is a swedish word meaning \"just the right amount\"."
   ],
   "metadata": {
    "collapsed": false,
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "22c0f078-416f-40e2-863b-0b01bc71b60c"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from maggy import experiment\n\nresult = experiment.lagom(train_fn=hpo_function, config=hpo_config)\n\nprint(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "86ed9262-c7b1-41b8-adb7-b85b5d2fc813"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">You are running Maggy on Databricks.\n\n------ RandomSearch Results ------ direction(max) \nBEST combination {&#34;number_layers&#34;: 6} -- metric 0.8999999761581421\nWORST combination {&#34;number_layers&#34;: 8} -- metric 0.6333333253860474\nAVERAGE metric -- 0.7749999910593033\nEARLY STOPPED Trials -- 0\nTotal job time 0 hours, 0 minutes, 17 seconds\n\nFinished experiment.\n{&#39;best_id&#39;: &#39;ce3a082c9201f474&#39;, &#39;best_val&#39;: 0.8999999761581421, &#39;best_config&#39;: {&#39;number_layers&#39;: 6}, &#39;worst_id&#39;: &#39;b334fd67693ed413&#39;, &#39;worst_val&#39;: 0.6333333253860474, &#39;worst_config&#39;: {&#39;number_layers&#39;: 8}, &#39;avg&#39;: 0.7749999910593033, &#39;metric_list&#39;: [0.6666666865348816, 0.8999999761581421, 0.8999999761581421, 0.6333333253860474], &#39;num_trials&#39;: 4, &#39;early_stopped&#39;: 0, &#39;num_epochs&#39;: 0, &#39;trial_id&#39;: &#39;ef1c8b938213a74d&#39;}\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">You are running Maggy on Databricks.\n\n------ RandomSearch Results ------ direction(max) \nBEST combination {&#34;number_layers&#34;: 6} -- metric 0.8999999761581421\nWORST combination {&#34;number_layers&#34;: 8} -- metric 0.6333333253860474\nAVERAGE metric -- 0.7749999910593033\nEARLY STOPPED Trials -- 0\nTotal job time 0 hours, 0 minutes, 17 seconds\n\nFinished experiment.\n{&#39;best_id&#39;: &#39;ce3a082c9201f474&#39;, &#39;best_val&#39;: 0.8999999761581421, &#39;best_config&#39;: {&#39;number_layers&#39;: 6}, &#39;worst_id&#39;: &#39;b334fd67693ed413&#39;, &#39;worst_val&#39;: 0.6333333253860474, &#39;worst_config&#39;: {&#39;number_layers&#39;: 8}, &#39;avg&#39;: 0.7749999910593033, &#39;metric_list&#39;: [0.6666666865348816, 0.8999999761581421, 0.8999999761581421, 0.6333333253860474], &#39;num_trials&#39;: 4, &#39;early_stopped&#39;: 0, &#39;num_epochs&#39;: 0, &#39;trial_id&#39;: &#39;ef1c8b938213a74d&#39;}\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Configure and run distributed training\n\n\nNow it's time to run the final step of our ML program. Let's initialize the configuration class for the distributed training. First, we need to define our hyperparameters, we want to take the best hyperparameters from the HPO."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "3b531eef-f446-4c06-85b5-7e258e8b96d0"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#define the constructor parameters of your model\nmodel_params = {\n    #train dataset entries / num_workers\n    'train_batch_size': 75,\n    #test dataset entries / num_workers\n    'test_batch_size': 15,\n    'learning_rate': 0.04,\n    'epochs': 20,\n    'number_layers': result['best_config']['number_layers'],\n}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "647635ae-b25b-4fc7-aa06-4f1b0ad816ca"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "TfDistributedConfig class contains the following parameters:\n* name: the name of the experiment.\n* module: the model to be trained (defined in the first step of this guideline).\n* train_set: the train set as a tuple (x_train, y_train) or the train set path.\n* test_set: the test set as a tuple (x_test, y_test) or the test set path.\n* process_data: the function to process the data (if needed).\n* hparams: the model and dataset parameters. In this case we also need to provide the 'train_batch_size' and the 'test_batch_size', these values represent the subset sizes of the sharded dataset. It's value is usually the dataset_size/number_workers but can change depending on your needs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "5e8cf9ac-289b-4743-bbca-cd362bddedf5"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from maggy.experiment_config.tf_distributed import TfDistributedConfig\n\ntraining_config = TfDistributedConfig(name=\"tf_test\", model=model, train_set=train_set, test_set=test_set, process_data=process_data, hparams = model_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "9d2422ac-8be8-45fd-8bbf-6e37badd4cac"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we are ready to launch the maggy experiment. You just need to pass 2 parameters: the training function and the configuration variable we defined in the previous steps."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "88ca9e39-1510-4d3c-8ad4-db8c4949810e"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment.lagom(training_function, training_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "application/vnd.databricks.v1+cell": {
     "title": "",
     "showTitle": false,
     "inputWidgets": {},
     "nuid": "a594363a-2bd9-41ed-ae28-770497b8b130"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Final average test loss: 0.346\nFinished experiment. Total run time: 0 hours, 0 minutes, 17 seconds\nOut[11]: {&#39;test result&#39;: 0.34621101431548595}</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Final average test loss: 0.346\nFinished experiment. Total run time: 0 hours, 0 minutes, 17 seconds\nOut[11]: {&#39;test result&#39;: 0.34621101431548595}</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "maggy-databricks-iris",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 1761503122828067
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}