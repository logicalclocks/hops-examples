{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Model Serving with KFServing and Tensorflow - MNIST Classification\"\n",
    "date: 2021-02-24\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serving with KFServing and Tensorflow - MNIST Classification\n",
    "---\n",
    "*INPUT --> MODEL --> PREDICTION*\n",
    "\n",
    "<font color='red'> <h3>This notebook requires KFServing to be installed</h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** It is assumed that a model called *mnist* is already available in Hopsworks. An example of training a model for the *MNIST handwritten digit classification problem* is available in `Jupyter/experiment/Tensorflow/mnist.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Serving on [Hopsworks](https://github.com/logicalclocks/hopsworks)\n",
    "\n",
    "![hops.png](../../../images/hops.png)\n",
    "\n",
    "### The `hops` python library\n",
    "\n",
    "`hops` is a helper library for Hops that facilitates development by hiding the complexity of running applications and iteracting with services.\n",
    "\n",
    "Have a feature request or encountered an issue? Please let us know on <a href=\"https://github.com/logicalclocks/hops-util-py\">github</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve the MNIST classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Repository for best model based on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image7-Monitor.png](../../../images/models.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Model Repository for best mnist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "\n",
    "conn = hsml.connection()\n",
    "mr = conn.get_model_registry()\n",
    "\n",
    "MODEL_NAME=\"mnist_e2e\"\n",
    "EVALUATION_METRIC=\"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = mr.get_best_model(MODEL_NAME, EVALUATION_METRIC, \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: mnist_e2e\n",
      "Model version: 1\n",
      "{'accuracy': '0.625'}\n"
     ]
    }
   ],
   "source": [
    "print('Model name: ' + best_model.name)\n",
    "print('Model version: ' + str(best_model.version))\n",
    "print(best_model.training_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Serving of Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 11:52:48,685 INFO: Serving mniste2ekf successfully created\n"
     ]
    }
   ],
   "source": [
    "# Create serving instance\n",
    "SERVING_NAME = \"mniste2ekf\"\n",
    "\n",
    "response = serving.create_or_update(SERVING_NAME, # define a name for the serving instance\n",
    "                                    model_path=best_model.model_path, # set the path of the model to be deployed\n",
    "                                    model_server=\"TENSORFLOW_SERVING\", # set the model server to run the model\n",
    "                                    kfserving=True, # whether to serve the model using KFServing or the default tool in the current Hopsworks version\n",
    "                                    # optional arguments\n",
    "                                    model_version=best_model.version, # set the version of the model to be deployed\n",
    "                                    topic_name=\"CREATE\", # (optional) set the topic name or CREATE to create a new topic for inference logging\n",
    "                                    inference_logging=\"ALL\", # with KFServing, select the type of inference data to log into Kafka, e.g MODEL_INPUTS, PREDICTIONS or ALL\n",
    "                                    instances=1, # with KFServing, set 0 instances to leverage scale-to-zero capabilities\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mniste2ekf\n"
     ]
    }
   ],
   "source": [
    "# List all available servings in the project\n",
    "for s in serving.get_all():\n",
    "    print(s.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopped'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get serving status\n",
    "serving.get_status(SERVING_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify digits with the MNIST classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Model Serving Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 11:52:49,378 INFO: Serving with name: mniste2ekf successfully started\n"
     ]
    }
   ],
   "source": [
    "if serving.get_status(SERVING_NAME) == 'Stopped':\n",
    "    serving.start(SERVING_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while serving.get_status(SERVING_NAME) != \"Running\":\n",
    "    time.sleep(5) # Let the serving startup correctly\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Serving for active servings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image7-Monitor.png](../../../images/servings.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Prediction Requests to the Served Model using Hopsworks REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [[0.00228863931, 0.039052885, 0.299541056, 0.0292527322, 0.210720837, 0.00816287566, 0.0126433428, 0.0109003522, 0.344060391, 0.0433768257]]}\n",
      "{'predictions': [[0.00586040691, 0.0307841301, 0.33769837, 0.0337129459, 0.254304558, 0.0237869881, 0.0141318291, 0.0193788894, 0.238279134, 0.0420627445]]}\n",
      "{'predictions': [[0.00538377091, 0.061361514, 0.238303721, 0.0285069272, 0.501042247, 0.0104929302, 0.0204542708, 0.0179179348, 0.0851745605, 0.0313620083]]}\n",
      "{'predictions': [[0.00573793799, 0.029261997, 0.369869381, 0.0178442206, 0.450838357, 0.00611973461, 0.00844837539, 0.0112320511, 0.079323791, 0.0213241577]]}\n",
      "{'predictions': [[0.0119106388, 0.0629702583, 0.153047368, 0.0336705893, 0.3950378, 0.00748524442, 0.0267426614, 0.0312577672, 0.249878481, 0.0279991794]]}\n",
      "{'predictions': [[0.0111142406, 0.0491779149, 0.204911619, 0.0337088816, 0.241256326, 0.0222033393, 0.0126153091, 0.0414450057, 0.302034378, 0.0815329328]]}\n",
      "{'predictions': [[0.00563503848, 0.0279151835, 0.28025192, 0.0385764167, 0.363024831, 0.0126688043, 0.0207744408, 0.0177768413, 0.193134412, 0.0402421467]]}\n",
      "{'predictions': [[0.00543945516, 0.126275226, 0.163412824, 0.04192359, 0.265003413, 0.0151998475, 0.0343197025, 0.0221705418, 0.241572261, 0.0846831948]]}\n",
      "{'predictions': [[0.00477044843, 0.0468725786, 0.208328143, 0.0335769281, 0.347728401, 0.0162629858, 0.0180092286, 0.01045975, 0.283724517, 0.0302670337]]}\n",
      "{'predictions': [[0.00746631622, 0.0523283072, 0.304017246, 0.027453661, 0.280292451, 0.0179669447, 0.0197735652, 0.0237298273, 0.174194977, 0.0927767605]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "NUM_FEATURES=784\n",
    "\n",
    "for i in range(10):\n",
    "    data = {\n",
    "                \"signature_name\": \"serving_default\", \"instances\": [np.random.rand(NUM_FEATURES).tolist()]\n",
    "            }\n",
    "    response = serving.make_inference_request(SERVING_NAME, data)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Prediction Requests and Responses using Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import kafka\n",
    "from confluent_kafka import Producer, Consumer, KafkaError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Kafka consumer and subscribe to the topic containing the prediction logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NAME = serving.get_kafka_topic(SERVING_NAME)\n",
    "\n",
    "config = kafka.get_kafka_default_config()\n",
    "config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "consumer = Consumer(config)\n",
    "topics = [TOPIC_NAME]\n",
    "consumer.subscribe(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Kafka Avro schema from Hopsworks and setup an Avro reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = kafka.get_schema(TOPIC_NAME)\n",
    "avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read messages from the Kafka topic, parse them with the Avro schema and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO -> servingId: 33, modelName: mnist_e2e, modelVersion: 1,requestTimestamp: 1643370799, inferenceId:8fe0ab82-a9fd-424e-b154-b88eaeb82312, messageType:response\n",
      "Predictions -> [[0.00531423138, 0.0495751873, 0.215446427, 0.0254741, 0.456469536, 0.00679346081, 0.0227076765, 0.0156853292, 0.151415035, 0.0511190034]]\n",
      "\n",
      "INFO -> servingId: 33, modelName: mnist_e2e, modelVersion: 1,requestTimestamp: 1643370799, inferenceId:2eb8f1b7-5fe5-4a15-921e-1077b3bc5548, messageType:response\n",
      "Predictions -> [[0.015544543, 0.04791224, 0.231773868, 0.0455554053, 0.352704018, 0.0196769126, 0.023360543, 0.0201557297, 0.190379784, 0.0529369563]]\n",
      "\n",
      "INFO -> servingId: 33, modelName: mnist_e2e, modelVersion: 1,requestTimestamp: 1643370799, inferenceId:2a85e0ed-70a4-43b3-8afd-43fdb5bb888c, messageType:response\n",
      "Predictions -> [[0.0119756339, 0.108432077, 0.249693975, 0.0291424617, 0.297212154, 0.0278416723, 0.0237392467, 0.0305440109, 0.182935417, 0.038483344]]\n",
      "\n",
      "INFO -> servingId: 33, modelName: mnist_e2e, modelVersion: 1,requestTimestamp: 1643370799, inferenceId:92f62e3a-f05e-442f-91c2-7f8de7d80de9, messageType:response\n",
      "Predictions -> [[0.0061565917, 0.0573133416, 0.157412216, 0.0603140071, 0.319210559, 0.01605873, 0.018614579, 0.0371795483, 0.204262689, 0.123477831]]\n",
      "\n",
      "INFO -> servingId: 33, modelName: mnist_e2e, modelVersion: 1,requestTimestamp: 1643370800, inferenceId:4c50013c-834d-4704-9808-6a6cb25dbb95, messageType:response\n",
      "Predictions -> [[0.011226072, 0.0487205796, 0.279118955, 0.0241690688, 0.347856402, 0.0182868, 0.0276911054, 0.0257906299, 0.145419195, 0.0717211664]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PRINT_INSTANCES=False\n",
    "PRINT_PREDICTIONS=True\n",
    "\n",
    "for i in range(0, 10):\n",
    "    msg = consumer.poll(timeout=5.0)\n",
    "    if msg is not None:\n",
    "        value = msg.value()\n",
    "        try:\n",
    "            event_dict = kafka.parse_avro_msg(value, avro_schema)  \n",
    "            payload = json.loads(event_dict[\"payload\"])\n",
    "            \n",
    "            if (event_dict['messageType'] == \"request\" and not PRINT_INSTANCES) or \\\n",
    "                (event_dict['messageType'] == \"response\" and not PRINT_PREDICTIONS):\n",
    "                continue\n",
    "            \n",
    "            print(\"INFO -> servingId: {}, modelName: {}, modelVersion: {},\"\\\n",
    "                  \"requestTimestamp: {}, inferenceId:{}, messageType:{}\".format(\n",
    "                       event_dict[\"servingId\"],\n",
    "                       event_dict[\"modelName\"],\n",
    "                       event_dict[\"modelVersion\"],\n",
    "                       event_dict[\"requestTimestamp\"],\n",
    "                       event_dict[\"inferenceId\"],\n",
    "                       event_dict[\"messageType\"]))\n",
    "\n",
    "            if event_dict['messageType'] == \"request\":\n",
    "                print(\"Instances -> {}\\n\".format(payload['instances']))\n",
    "                \n",
    "            if event_dict['messageType'] == \"response\":\n",
    "                print(\"Predictions -> {}\\n\".format(payload['predictions']))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"A message was read but there was an error parsing it\")\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"timeout.. no more messages to read from topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}